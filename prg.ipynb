{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "name": "prg.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDjZlp1mHLxt"
      },
      "source": [
        "PREPROCESSING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2etF2APqHLxu"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pandas import read_csv"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Co7oDnVgHLx0"
      },
      "source": [
        "\n",
        "df1=pd.read_csv(\"AllFeb21-fraud.csv\")\n",
        "df2=pd.read_csv(\"AllFeb21-click.csv\")\n",
        "df2=df2.sample(frac=0.06)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUWV0LJCHLx4"
      },
      "source": [
        "df=pd.concat([df1,df2], sort = False, axis=0, join='outer')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_JCgG3AHLx7"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQw0M3g8HLx_"
      },
      "source": [
        "df = df.sample(frac=1).reset_index(drop=True) # shuffle the dataset\n",
        "# print(df['fraud'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Tga61qwHLyD"
      },
      "source": [
        "#dropping unnecesary\n",
        "df=df.drop('bundleId',axis=1)#NR\n",
        "df=df.drop('refUrl',axis=1)#NR\n",
        "df=df.drop('fraudReason',axis=1)#NR\n",
        "\n",
        "df=df.drop('auds',axis=1)#COMPLEX\n",
        "df=df.drop('callIdentifier',axis=1)#COMPLEX\n",
        "df=df.drop('section',axis=1)#COMPLEX\n",
        "df=df.drop('ctxCatId',axis=1)#COMPLEX\n",
        "df=df.drop('clickXForwardedFor',axis=1)#COMPLEX\n",
        "\n",
        "df=df.drop('crtd',axis=1)#CONST\n",
        "df=df.drop('paid',axis=1)#CONST\n",
        "df=df.drop('esi',axis=1)#CONST"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qke0ijeVHLyG"
      },
      "source": [
        "# Encoding the Independent Variable - id\n",
        "labelencoder_X = LabelEncoder()\n",
        "df.id = labelencoder_X.fit_transform(df.id)\n",
        "\n",
        "# Encoding the Independent Variable - timestamp\n",
        "labelencoder_X = LabelEncoder()\n",
        "df.timestamp = labelencoder_X.fit_transform(df.timestamp)\n",
        "\n",
        "# Encoding the Independent Variable - imprId\n",
        "labelencoder_X = LabelEncoder()\n",
        "df.imprId = labelencoder_X.fit_transform(df.imprId)\n",
        "\n",
        "# Encoding the Independent Variable - clmbUserId\n",
        "labelencoder_X = LabelEncoder()\n",
        "df.clmbUserId = labelencoder_X.fit_transform(df.clmbUserId)\n",
        "\n",
        "# Encoding the Independent Variable - clickIp\n",
        "labelencoder_X = LabelEncoder()\n",
        "df.clickIp = labelencoder_X.fit_transform(df.clickIp)\n",
        "\n",
        "# Encoding the Independent Variable - impressionServedTimeStamp\n",
        "labelencoder_X = LabelEncoder()\n",
        "df.impressionServedTimeStamp = labelencoder_X.fit_transform(df.impressionServedTimeStamp)\n",
        "\n",
        "# Encoding the Independent Variable - ip\n",
        "labelencoder_X = LabelEncoder()\n",
        "df.ip = labelencoder_X.fit_transform(df.ip)\n",
        "\n",
        "# Encoding the Independent Variable - userAgent\n",
        "labelencoder_X = LabelEncoder()\n",
        "df.userAgent = labelencoder_X.fit_transform(df.userAgent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gbmmOVd6HLyM"
      },
      "source": [
        "#Imputation\n",
        "\n",
        "# mark zero values as missing or NaN\n",
        "df =df.replace(0, np.NaN)\n",
        "# fill missing values with mean column values\n",
        "df.fillna(df.mean(), inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YkvXM8NYHLyP"
      },
      "source": [
        "# Encoding the Independent Variable - fraud #this is done after imputation else all these zeros will be replaced by 1s\n",
        "labelencoder_X = LabelEncoder()\n",
        "df.fraud= labelencoder_X.fit_transform(df.fraud)\n",
        "# print(df['fraud'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xthkMTCHLyS"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler= MinMaxScaler(feature_range=(0, 100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyDc00HDHLyW"
      },
      "source": [
        "df.columns.values\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7Yq-5hGHLya"
      },
      "source": [
        "cor = df.corr()\n",
        "cor_sorted = cor.sort_values(by=['fraud'], ascending=False).iloc[:,14] #sorting the features to show high corelated features (with fraud) on the top\n",
        "# cor_sorted"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1Lq_E9DHLyd"
      },
      "source": [
        "# position                     0.021268\n",
        "# connTypeDimId                0.014521\n",
        "# advClientId                  0.001073\n",
        "# clickGeoId                  -0.001880\n",
        "# clmbUserId                  -0.013623\n",
        "# imprId                      -0.018225\n",
        "# these can be removed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSWWRM_sHLyh"
      },
      "source": [
        "sp_cor = df.corr(method='spearman')\n",
        "sp_cor_sorted = sp_cor.sort_values(by=['fraud'], ascending=False).iloc[:,14] #sorting the features to show high spearman corelated features (with fraud) on the top"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vr5feuh-HLyk"
      },
      "source": [
        "array = df.values\n",
        "x_cols = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31]\n",
        "# store the feature matrix (X) and response vector (y)\n",
        "X = array[:,x_cols]\n",
        "Y = array[:,14]\n",
        "\n",
        "# splitting X and y into training and testing sets\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxVZd5q2HLyn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDPmw_MYHLyq"
      },
      "source": [
        "#to print confusion matrix\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "#to print metrics\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_aDGC-hHLyu"
      },
      "source": [
        "GAUSSIAN NAIVEBAYES CLASSIFIER - without normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRzi3X9_HLyv"
      },
      "source": [
        "# training the model on training set\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, Y_train)\n",
        "\n",
        "# making predictions on the testing set\n",
        "Y_pred = gnb.predict(X_test)\n",
        "\n",
        "# comparing actual response values (y_test) with predicted response values (y_pred)\n",
        "from sklearn import metrics\n",
        "# print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(Y_test, Y_pred)*100)\n",
        "\n",
        "#Confusion matrix and various metrics of GNB classifer\n",
        "\n",
        "results = confusion_matrix(Y_test, Y_pred)\n",
        "print ('Confusion Matrix of GNB Classifier:')\n",
        "print(results)\n",
        "print ('Accuracy Score :',accuracy_score(Y_test, Y_pred))\n",
        "print ('Report : ')\n",
        "print (classification_report(Y_test, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be7oIQgUHLyy"
      },
      "source": [
        "SVM - without normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fpb3W3ZFHLyz"
      },
      "source": [
        "# from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
        "# clf = SVC(kernel='linear')\n",
        "\n",
        "# # fitting x samples and y classes\n",
        "# clf.fit(X_train, Y_train)\n",
        "# Y_pred = clf.predict(X_test)\n",
        "\n",
        "# # comparing actual response values (y_test) with predicted response values (y_pred)\n",
        "# print(\"SVM accuracy(in %):\", metrics.accuracy_score(Y_test, Y_pred)*100)\n",
        "\n",
        "# results = confusion_matrix(Y_test, Y_pred)\n",
        "# print ('Confusion Matrix SVM:')\n",
        "# print(results)\n",
        "# print ('Accuracy Score :',accuracy_score(Y_test, Y_pred))\n",
        "# print ('Report : ')\n",
        "# print (classification_report(Y_test, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4nOLEyo-HLy2"
      },
      "source": [
        "LOGISTIC REGRESSION - without normalisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02ZXI1RdHLy2"
      },
      "source": [
        "from sklearn import linear_model\n",
        "logreg = linear_model.LogisticRegression(C=1e5)\n",
        "logreg.fit(X_train, Y_train)\n",
        "Y_pred = logreg.predict(X_test)\n",
        "# Put the result into a color plot\n",
        "\n",
        "# print(\"Logistic Regression accuracy(in %):\", metrics.accuracy_score(Y_test, Y_pred)*100)\n",
        "\n",
        "results = confusion_matrix(Y_test, Y_pred)\n",
        "print ('Confusion Matrix SVM:')\n",
        "print(results)\n",
        "print ('Accuracy Score :',accuracy_score(Y_test, Y_pred))\n",
        "print ('Report : ')\n",
        "print (classification_report(Y_test, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2W0QLm5HLy5"
      },
      "source": [
        "Normalising data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tw69rrbEHLy5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcTRgwEIHLy-"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler= MinMaxScaler(feature_range=(0, 100))\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmp0ju8YHLzA"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "sc_X = StandardScaler()\n",
        "X_train = sc_X.fit_transform(X_train)\n",
        "X_test = sc_X.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B-Gaeto0HLzF"
      },
      "source": [
        "GNB CLASSIFIER - normalised input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "en49CL0uHLzG"
      },
      "source": [
        "# training the model on training set\n",
        "# from sklearn.naive_bayes import GaussianNB\n",
        "# gnb = GaussianNB()\n",
        "gnb.fit(X_train, Y_train)\n",
        "# making predictions on the testing set\n",
        "Y_pred = gnb.predict(X_test)\n",
        "\n",
        "# comparing actual response values (y_test) with predicted response values (y_pred)\n",
        "from sklearn import metrics\n",
        "print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(Y_test, Y_pred)*100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wILT7JXzHLzK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QI6pBh-HLzN"
      },
      "source": [
        "#Confusion matrix and various metrics of GNB classifer\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "results = confusion_matrix(Y_test, Y_pred)\n",
        "print ('Confusion Matrix of GNB Classifier:')\n",
        "print(results)\n",
        "print ('Accuracy Score :',accuracy_score(Y_test, Y_pred))\n",
        "print ('Report : ')\n",
        "print (classification_report(Y_test, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PW0KWIQMHLzQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBtF5u8OHLzS"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFcBttz0HLzS"
      },
      "source": [
        "SVM - normalised input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evME8ae2HLzT"
      },
      "source": [
        "from sklearn.svm import SVC # \"Support Vector Classifier\"\n",
        "clf = SVC(kernel='linear')\n",
        "\n",
        "# fitting x samples and y classes\n",
        "clf.fit(X_train, Y_train)\n",
        "Y_pred = clf.predict(X_test)\n",
        "\n",
        "# comparing actual response values (y_test) with predicted response values (y_pred)\n",
        "# print(\"SVM accuracy(in %):\", metrics.accuracy_score(Y_test, Y_pred)*100)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "results = confusion_matrix(Y_test, Y_pred)\n",
        "print ('Confusion Matrix SVM:')\n",
        "print(results)\n",
        "print ('Accuracy Score :',accuracy_score(Y_test, Y_pred))\n",
        "print ('Report : ')\n",
        "print (classification_report(Y_test, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OAJYpPUHLzW"
      },
      "source": [
        "LOGISTIC REGRESSION - normalised input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oKA4l1AHLzW"
      },
      "source": [
        "from sklearn import linear_model\n",
        "logreg = linear_model.LogisticRegression(C=1e5)\n",
        "logreg.fit(X_train, Y_train)\n",
        "Y_pred = logreg.predict(X_test)\n",
        "# Put the result into a color plot\n",
        "\n",
        "# print(\"Logistic Regression accuracy(in %):\", metrics.accuracy_score(Y_test, Y_pred)*100)\n",
        "\n",
        "# from sklearn.metrics import confusion_matrix\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.metrics import classification_report\n",
        "\n",
        "results = confusion_matrix(Y_test, Y_pred)\n",
        "print ('Confusion Matrix Logistic regression :')\n",
        "print(results)\n",
        "print ('Accuracy Score :',accuracy_score(Y_test, Y_pred))\n",
        "print ('Report : ')\n",
        "print (classification_report(Y_test, Y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6MdKzV6iHLza"
      },
      "source": [
        "DEEP LEARNING"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SCZFC2iHLza"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# from pandas import read_csv\n",
        "# import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.layers import BatchNormalization\n",
        "import pylab as plt\n",
        "import h5py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3VHfzUoHLzd"
      },
      "source": [
        "import sklearn.metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZMVaV1ZHLzg"
      },
      "source": [
        "\n",
        "batch_size = 128\n",
        "num_classes = 2\n",
        "epochs = 30\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ifi_dKWHLzi"
      },
      "source": [
        "# convert class vectors to binary class matrices\n",
        "Y_train = keras.utils.to_categorical(Y_train, num_classes)\n",
        "Y_test = keras.utils.to_categorical(Y_test, num_classes)\n",
        "\n",
        "# Y_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVifhYB3HLzl"
      },
      "source": [
        "#building NN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydxgSN7vHLzo"
      },
      "source": [
        "first_layer_size = 31\n",
        "model = Sequential()\n",
        "model.add(Dense(first_layer_size, activation='relu', input_shape=(31,)))\n",
        "model.add(Dense(32, activation='sigmoid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(25, activation='sigmoid'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(16, activation='sigmoid'))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VW0ZEGYAHLzq"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(), metrics=['accuracy'])\n",
        "classifier = model.fit(X_train, Y_train, batch_size=batch_size, epochs=epochs,verbose=0,validation_data=(X_test, Y_test))\n",
        "score = model.evaluate(X_test, Y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCD4LkcQHLzu"
      },
      "source": [
        "#print(x_test[1:2].shape)\n",
        "predictions = model.predict(X_test)\n",
        "# prediction = prediction[0]\n",
        "print('Prediction\\n',predictions)\n",
        "thr_pred =(predictions>0.5)*1\n",
        "print('Thresholded output\\n',thr_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urzaQkgBHLzw"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# results = confusion_matrix(Y_test, l)\n",
        "results = confusion_matrix(Y_test.argmax(axis=1), predictions.argmax(axis=1))\n",
        "print ('Confusion Matrix of Neural network:')\n",
        "print(results)\n",
        "print ('Accuracy Score :',accuracy_score(Y_test.argmax(axis=1), predictions.argmax(axis=1)))\n",
        "print ('Report : ')\n",
        "print (classification_report(Y_test.argmax(axis=1), predictions.argmax(axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uhUetQlJHLz2"
      },
      "source": [
        "model.save_weights('model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFuxMGQ2HLz5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "fig = plt.gcf()\n",
        "plt.plot(classifier.history['acc'])\n",
        "plt.plot(classifier.history['val_acc'])\n",
        "plt.title(\"Accuracy Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['train','test'], loc=\"upper left\")\n",
        "plt.show()\n",
        "fig.savefig(\"Model_Accuracy_Curves.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fu8bDchvHLz_"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "fig = plt.gcf()\n",
        "plt.plot(classifier.history['loss'])\n",
        "plt.plot(classifier.history['val_loss'])\n",
        "plt.title(\"Log Loss Curve\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend(['train','test'], loc=\"upper left\")\n",
        "plt.show()\n",
        "fig.savefig(\"Model_Loss_Curves.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IyvIOlEuHL0E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}